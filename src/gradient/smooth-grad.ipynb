{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739053fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "from captum.attr import  GuidedBackprop\n",
    "\n",
    "# Helper functions\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.visualise import display_imagenet_output, process_attributions\n",
    "from utils.datasets import preprocess_imagenet_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7824722c",
   "metadata": {},
   "source": [
    "## Load model and sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fcb352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download example image\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.download import save_image\n",
    "\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/4/4b/Israel-2013-Makhtesh_Ramon_02_%28Ibex%29.jpg\"\n",
    "save_image(url, \"goat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6299778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample image\n",
    "img_path = \"goat.png\"\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model (e.g., ResNet50)\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Set the model to gpu\n",
    "device = torch.device('mps' if torch.backends.mps.is_built()\n",
    "                      else 'cuda' if torch.cuda.is_available()\n",
    "                      else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a74bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "original_img_tensor = preprocess_imagenet_image(img_path)\n",
    "original_img_tensor = original_img_tensor.to(device)\n",
    "\n",
    "# Clone tensor to avoid in-place operations\n",
    "img_tensor = original_img_tensor.clone()\n",
    "img_tensor.requires_grad_() # Enable gradient tracking\n",
    "\n",
    "predictions = model(img_tensor)\n",
    "\n",
    "# Decode the output\n",
    "display_imagenet_output(predictions,n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603b7151",
   "metadata": {},
   "source": [
    "## SmoothGrad + Standard Backpropogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb5183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset gradients\n",
    "model.zero_grad()\n",
    "\n",
    "# We will use this class for all gradient computations\n",
    "target_class = predictions.argmax()\n",
    "\n",
    "# Compute gradients w.r.t to logit by performing backward pass\n",
    "predictions[:, target_class].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the gradients\n",
    "standard_backprop_grads = img_tensor.grad.detach().cpu().numpy()\n",
    "\n",
    "grads = standard_backprop_grads[0].copy()\n",
    "grads = process_attributions(grads, activation=\"abs\",skew= 0.5, colormap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cabd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_samples = 50  # number of noisy samples\n",
    "noise_sigma = 0.15 * (img_tensor.max()- img_tensor.min()).item() # standard deviation of noise\n",
    "\n",
    "# SmoothGrad computation\n",
    "smooth_grads = torch.zeros_like(original_img_tensor)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Add noise to original image\n",
    "    noise = torch.randn_like(original_img_tensor) * noise_sigma\n",
    "    noisy_img = original_img_tensor + noise\n",
    "    noisy_img.requires_grad_()\n",
    "\n",
    "    # Reset gradients to be safe\n",
    "    if noisy_img.grad is not None:\n",
    "        noisy_img.grad.zero_()\n",
    "\n",
    "    # Forward pass\n",
    "    preds = model(noisy_img)\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    preds[:, target_class].backward()\n",
    "\n",
    "    # Get gradients\n",
    "    noisy_grad = noisy_img.grad\n",
    "\n",
    "    # Accumulate gradients\n",
    "    smooth_grads += noisy_grad\n",
    "\n",
    "smooth_grads /= n_samples\n",
    "\n",
    "# Convert to numpy\n",
    "smooth_grads_np = smooth_grads.detach().cpu().numpy()[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cee4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process attribution map (same as your existing function)\n",
    "smoothgrad_map = process_attributions(smooth_grads_np, activation=\"abs\", skew=0.5, colormap=\"viridis\")\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title(\"Input Image\")\n",
    "ax[1].imshow(grads)\n",
    "ax[1].set_title(\"Gradients\")\n",
    "ax[2].imshow(smoothgrad_map)\n",
    "ax[2].set_title(f\"SmoothGrad + Gradients\")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7583a5b8",
   "metadata": {},
   "source": [
    "## SmoothGrad + Guided Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0216072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = original_img_tensor.clone()\n",
    "img_tensor.requires_grad_()\n",
    "\n",
    "#  Guided Backprop\n",
    "guided_bp = GuidedBackprop(model)\n",
    "gb_attr = guided_bp.attribute(img_tensor, target=target_class)\n",
    "\n",
    "gb_attr = process_attributions(gb_attr, activation=\"abs\", skew=0.5, colormap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd743cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50         # number of noisy samples\n",
    "noise_sigma = 0.15 * (original_img_tensor.max() - original_img_tensor.min()).item() # standard deviation of noise\n",
    "\n",
    "# SmoothGrad + Guided Backpropagation\n",
    "smooth_grads_gb = torch.zeros_like(original_img_tensor)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Add Gaussian noise to original image\n",
    "    noise = torch.randn_like(original_img_tensor) * noise_sigma\n",
    "    noisy_img = original_img_tensor + noise\n",
    "    noisy_img.requires_grad_()\n",
    "\n",
    "     # Reset gradients to be safe\n",
    "    if noisy_img.grad is not None:\n",
    "        noisy_img.grad.zero_()\n",
    "\n",
    "    # Guided Backpropagation\n",
    "    guided_bp = GuidedBackprop(model)\n",
    "    gb_attr_noisy = guided_bp.attribute(noisy_img, target=target_class)\n",
    "\n",
    "    # Accumulate gradients\n",
    "    smooth_grads_gb += gb_attr_noisy.detach()\n",
    "\n",
    "# Average the accumulated gradients\n",
    "smooth_grads_gb /= n_samples\n",
    "\n",
    "# Convert to numpy\n",
    "smooth_grads_gb_np = smooth_grads_gb.detach().cpu().numpy()[0]\n",
    "\n",
    "\n",
    "# Process attribution map\n",
    "smoothgrad_gb_map = process_attributions(smooth_grads_gb_np, activation=\"abs\", skew=0.5, colormap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be273003",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title(\"Input Image\")\n",
    "\n",
    "ax[1].imshow(gb_attr)\n",
    "ax[1].set_title(\"GBP\")\n",
    "\n",
    "ax[2].imshow(smoothgrad_gb_map)\n",
    "ax[2].set_title(\"SmoothGrad + GBP\")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XAI for CV",
   "language": "python",
   "name": "cv_xai_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}